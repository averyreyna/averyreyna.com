---
title: 'Help Supporters'
publishedAt: '2024-05-11'
summary: 'Summary about the Help Supporters project.'
---

Help Supporters is the second project I worked on at Columbia University in Brian Smith's lab, published at CHI 2024.

*Help Supporters explores how technology can bridge the social gap between blind people and sighted strangers who want to help them.*

What do I mean by that?

Consider how often you see a blind person getting help from a stranger in public. It's surprisingly rare, right? Yet platforms like BeMyEyes have 13 times more sighted volunteers than blind users. This reveals a fascinating paradox: while many sighted people are eager to help, face-to-face assistance rarely happens due to complex social barriers affecting both parties. Our research investigates how thoughtfully designed technology could facilitate these interactions.

<Video src="/help_supporters/help_supporters_presentation.mp4" />

## The Challenge of Public Space Assistance

The paradox of public assistance for blind and low-vision (BLV) individuals presents a compelling challenge in accessibility research. While many sighted people are eager to help BLV individuals—as evidenced by platforms like BeMyEyes, which has thirteen times more sighted volunteers than BLV users—face-to-face assistance in public spaces remains surprisingly rare. This disconnect stems not from technological limitations but from complex social barriers affecting both parties. BLV individuals often experience anxiety about approaching and asking strangers for help, while sighted people frequently struggle with uncertainty about when and how to offer assistance. Even when help does occur, both parties face significant challenges in effective communication and boundary respect.

## Project Overview and Research Goals

We explored innovative technological approaches to facilitate face-to-face help between BLV and sighted strangers by systematically investigating the entire help process. Through extensive mixed-ability research-through-design methodology, we developed and evaluated four distinct prototypes that address different aspects of help interactions. Our approach recognizes that successful assistance comprises two critical phases: the connection phase, where help is initially sought and offered, and the collaboration phase, where aid is actively provided.

The research specifically aimed to answer four crucial questions: how technology should facilitate the initial connection between BLV and sighted individuals, what information should be exchanged during this connection, what types of information should be provided during the actual helping process, and how this information should be presented to maximize effectiveness while maintaining social comfort.

## Connection Phase Approaches

The Person-Finder Glasses represent our first approach to facilitating initial connections between BLV individuals and potential helpers. This HoloLens-based solution empowers BLV users with unprecedented agency in locating potential helpers in their environment. The system employs sophisticated computer vision technology to detect nearby individuals and provides audio cues that guide BLV users toward them. The audio feedback system is designed to support natural walking patterns and appropriate social distance maintenance, enabling more confident and socially acceptable approaches to potential helpers.

<Image 
  src="/help_supporters/person_finder_glasses.png"
  alt="'Person-Finder Glasses prototype"
  width={800}
  height={600}
  caption="Left: A BLV user (in blue) wearing the Person-Finder Glasses to locate and greet a nearby stranger (in red) in a public environment. Right: A plan view diagram showing how the Person-Finder Glasses support the BLV user (in blue) to detect a nearby stranger (in red) and display auditory cues."
/>

The Volunteer Platform takes a fundamentally different approach to the connection challenge. This mobile application creates a structured environment for matching BLV users with nearby sighted volunteers. The platform allows BLV users to articulate specific needs, time requirements, and preferences, while sighted volunteers can indicate their availability, experience level, and location. This system addresses social anxiety in both direct approaches and unsolicited help offers by creating a mutually consensual framework for assistance.

## Collaboration Phase Approaches

The Pictorial Display prototype represents a novel approach to improving help quality once a connection is established. This wearable screen, mounted on the BLV user's chest, displays real-time guidance using carefully designed Bitmoji illustrations. The system serves multiple purposes: it provides immediate feedback to sighted helpers about their assistance techniques, creates a more lighthearted atmosphere during interactions, and helps establish clear communication protocols. The visual messaging system was designed to be informative and socially acceptable, with content carefully calibrated to maintain the dignity of both parties.

The Vague Directions Flagger addresses the common problem of imprecise or visually dependent language in help situations. This smartphone application actively monitors sighted helpers' speech in real-time, employing sophisticated natural language processing to identify potentially problematic phrases or descriptions. When vague or confusing language is detected, the system suggests more specific alternatives to the sighted helper. This approach allows for immediate correction of common communication issues while avoiding public embarrassment or disruption of social interaction.

## Technical Implementation

Each prototype represents a unique technical approach to supporting help interactions:

**Person-Finder Glasses**:
- Built using Unity on Microsoft HoloLens (1st generation)
- Incorporates Microsoft Holographic Face Tracker for detection
- Real-time visual data processing for face detection
- Spatial audio system for directional guidance
- Audio feedback calibrated for natural walking patterns
- Continuous distance monitoring for social spacing

**Volunteer Platform**:
- Web application built with React.js
- Responsive design for mobile-first interaction
- Real-time location-based matching system
- User profile management and preferences storage
- Accessibility-focused interface design
- Secure communication channel between users

**Pictorial Display**:
- Wearable smartphone screen implementation
- Custom-built control dashboard in HTML/JavaScript
- Bitmoji integration for visual feedback
- Real-time message selection algorithm
- Remote control system for study facilitators
- Display optimization for public visibility

**Vague Directions Flagger**:
- React.js-based smartphone application
- Real-time speech-to-text processing
- Natural language analysis for vague terms
- Pattern matching against phrase database
- Private feedback delivery system
- Context-aware suggestion generation

## Study Design

Our evaluation involved a carefully designed mixed-ability study with 20 participants, evenly split between BLV individuals with varying levels of visual impairment and sighted university students. The study methodology was structured to gather comprehensive data about the prototypes' technical effectiveness and impact on social interaction dynamics.

Each two-hour study session paired BLV and sighted participants to test all four prototypes in realistic public spaces, including building lobbies, lounges, and cafes. The study began with detailed pre-study interviews about past help experiences, followed by carefully structured prototype testing sessions. The testing phase employed Wizard-of-Oz techniques where necessary to ensure consistent functionality while gathering authentic interaction data.

The study environment selection was intentionally varied to capture data about how the prototypes performed in different social and physical contexts. Experimenters coordinated the interactions throughout the sessions, maintaining careful control over testing conditions while allowing natural interaction patterns to emerge.

## Connection Phase Insights

The study revealed a strong preference among BLV and sighted participants for the app-based Volunteer Platform over the Person-Finder Glasses. This preference was primarily driven by the platform's ability to reduce social pressure through discrete interaction options. Potential helpers particularly valued the ability to decline requests without direct confrontation, while BLV users appreciated the ability to review helper profiles before initiating contact.

The research uncovered essential insights about information preferences during the connection phase. BLV users particularly emphasized the importance of knowing potential helpers' experience with BLV individuals, with some explicitly preferring female helpers for comfort and safety reasons. Both groups stressed the importance of understanding each other's availability and knowledge level before initiating help interactions.

## Collaboration Phase Insights

During the collaboration phase, sighted helpers showed a strong appreciation for specific corrections about their language and directions, finding the visual examples through Bitmoji illustrations especially effective. Content that helped them empathize with BLV experiences proved crucial for improving assistance quality. A notable finding was that while helpers wanted validation of their performance, they strongly preferred to receive feedback about mistakes privately.

The study revealed complex interactions between eye contact, environmental awareness, and information display. Sighted helpers needed to maintain eye contact while simultaneously viewing their surroundings and any supplementary information provided by the help supporters. This balance proved crucial for successful interactions and influenced preferences for information display methods.

<Image 
  src="/help_supporters/interdependence_framwork.png"
  alt="'Person-Finder Glasses prototype"
  width={800}
  height={600}
  caption="A three-panel diagram showing how assistive technology (AT) facilitates interaction between blind/low vision (BLV) and sighted individuals. (A) shows general interdependence between people and environment, (B) depicts AT connecting BLV and sighted individuals, and (C) illustrates AT guiding the sighted person to help communicate environmental information to the BLV person."
/>

## Broader Implications

The findings from this research have significant implications for the design of assistive technologies that aim to facilitate social interaction. The success of the platform-based approach suggests that technological interventions in social assistance should focus on creating structured environments for interaction while maintaining user autonomy and dignity.

The research also demonstrates the importance of considering technical and social aspects in assistive technology design. The most successful prototypes balanced practical functionality with social acceptability, suggesting a framework for future developments in this field.

These findings contribute to understanding how technology can bridge social gaps while respecting and enhancing human interaction patterns. As cities and public spaces become increasingly complex, the role of such supportive technologies in facilitating inclusive social interaction becomes increasingly crucial.